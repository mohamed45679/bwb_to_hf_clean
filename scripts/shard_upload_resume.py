#!/usr/bin/env python3
"""
shard_upload_resume.py
----------------------
ÙŠØ³ØªØ£Ù†Ù Ø±ÙØ¹ Ø´Ø¸Ø§ÙŠØ§ JSONL Ø¥Ù„Ù‰ Ù…Ø³ØªÙˆØ¯Ø¹ Hugging Face (Ù†ÙˆØ¹: dataset) Ø¨Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰
Ù…Ù„Ù progress Ù…Ø­Ù„ÙŠ (upload_progress.json). Ø¨Ø¹Ø¯ Ø±ÙØ¹ ÙƒÙ„ Ø´Ø¸ÙŠÙ‘Ø© Ù†Ø§Ø¬Ø­Ø© ÙŠØ­Ø¯Ù‘Ø«
Ø§Ù„Ù…Ø¤Ø´Ù‘Ø± Ø«Ù… ÙŠØªØ§Ø¨Ø¹ Ø­ØªÙ‘Ù‰ ÙŠÙ†ØªÙ‡ÙŠ Ø£Ùˆ ÙŠØ­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù‚Ø§Ø¨Ù„ Ù„Ù„Ø§Ø³ØªØ±Ø¯Ø§Ø¯.

Ø§Ù„ÙˆØ³ÙŠØ·Ø§Øª:
  --repo_id    Ù…Ø³Ø§Ø± Ø§Ù„Ø±ÙŠØ¨Ùˆ Ø¹Ù„Ù‰ ğŸ¤— (Ù…Ø«Ø§Ù„: vGassen/Dutch-Basisbestandwetten-Legislation-Laws)
  --token      HF_TOKEN Ø¨ØµÙ„Ø§Ø­ÙŠØ© ÙƒØªØ§Ø¨Ø©
  --shard_size Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª ÙÙŠ ÙƒÙ„ Ø´Ø¸ÙŠÙ‘Ø© (Ø§ÙØªØ±Ø§Ø¶ÙŠ 500)
  --data_dir   Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù€ XML (Ø§ÙØªØ±Ø§Ø¶ÙŠ ../data)
"""
from __future__ import annotations
from ast import main
import os, json, glob, argparse, time, tempfile, sys
from typing import List
from huggingface_hub import HfApi, create_repo

# ---------------- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ---------------- #
PROGRESS_FILE = "upload_progress.json"
RETRY_LIMIT   = 5
BACKOFF       = 2.0         # Ø«ÙˆØ§Ù†Ù Ø¨ÙŠÙ† Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª

# ---------------- Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© ---------------- #
def load_progress() -> int:
    if os.path.exists(PROGRESS_FILE):
        with open(PROGRESS_FILE, encoding="utf-8") as f:
            try:
                return json.load(f)["last_index"]
            except Exception:
                pass
    return 0

def save_progress(idx: int):
    with open(PROGRESS_FILE, "w", encoding="utf-8") as f:
        json.dump({"last_index": idx}, f)

def list_xml(data_dir: str) -> List[str]:
    return sorted(glob.glob(os.path.join(data_dir, "**", "*.xml"), recursive=True))

def xml_to_record(path: str) -> dict:
    rel = os.path.relpath(path, start=os.path.dirname(data_dir)).replace("\\", "/")
    with open(path, "rb") as f:
        content = f.read().decode("utf-8", "ignore")
    return {"url": rel, "content": content, "source": "Basis Wettenbestand"}

def build_jsonl(batch: List[str]) -> str:
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".jsonl").name
    with open(tmp, "w", encoding="utf-8") as out:
        for fp in batch:
            out.write(json.dumps(xml_to_record(fp), ensure_ascii=False) + "\n")
    return tmp

# ---------------- Ø¯Ø§Ù„Ø© Ø§Ù„Ø±ÙØ¹ Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© ---------------- #
def upload_shard(buf_path: str, shard_name: str, api: HfApi,
                 repo_id: str, token: str) -> bool:
    for attempt in range(1, RETRY_LIMIT + 1):
        try:
            api.upload_file(
                path_or_fileobj = buf_path,
                path_in_repo    = shard_name,
                repo_id         = repo_id,
                repo_type       = "dataset",     # â† Ù…Ù‡Ù…
                token           = token
            )
            return True
        except Exception as e:
            if attempt == RETRY_LIMIT:
                print(f"ÙØ´Ù„ Ø±ÙØ¹ {shard_name}: {e}")
                return False
            time.sleep(BACKOFF * attempt)
    return False

# ---------------- Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³Ù‰ ---------------- #
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Resume shard upload to ğŸ¤— dataset")
    parser.add_argument("--repo_id", required=True)
    parser.add_argument("--token",   required=False, default=os.getenv("HF_TOKEN"))
    parser.add_argument("--shard_size", type=int, default=250)
    parser.add_argument("--data_dir",
                        default=os.path.join(os.path.dirname(__file__), "..", "data"))
    args = parser.parse_args()

    if not args.token:
        sys.exit("ÙŠØ¬Ø¨ Ø¶Ø¨Ø· HF_TOKEN Ø£Ùˆ ØªÙ…Ø±ÙŠØ±Ù‡ Ø¨Ù€ --token")

    data_dir = os.path.abspath(args.data_dir)
    files    = list_xml(data_dir)
    total    = len(files)
    if total == 0:
        sys.exit(f"Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª XML ÙÙ‰ {data_dir}")

    api = HfApi()
    create_repo(args.repo_id, repo_type="dataset", exist_ok=True, token=args.token)

    start = load_progress()
    if start >= total:
        print("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø´Ø¸Ø§ÙŠØ§ Ø¬Ø¯ÙŠØ¯Ø© â€” ÙƒÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø±ÙÙØ¹Øª.")
        sys.exit(0)

    print(f"ÙŠØ¨Ø¯Ø£ Ø§Ù„Ø±ÙØ¹ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„ {start} / {total}")
    for i in range(start, total, args.shard_size):
        batch      = files[i:i + args.shard_size]
        shard_name = f"shards/shard_{i:06d}_{i + len(batch):06d}.jsonl"

        tmp = build_jsonl(batch)
        ok  = upload_shard(tmp, shard_name, api, args.repo_id, args.token)
        os.remove(tmp)

        if not ok:
            print("ØªÙˆÙ‚Ù‘Ù Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø¨Ø¹Ø¯ Ø£Ø®Ø·Ø§Ø¡ Ù…ØªÙƒØ±Ù‘Ø±Ø©.")
            break

        save_progress(i + len(batch))
        print(f"ØªÙ… Ø±ÙØ¹ {shard_name} (Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ {i + len(batch)}/{total})")

    print("ØªÙ…Ù‘Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø±ÙØ¹.")

if __name__ == "__main__":
    main()
